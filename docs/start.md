

## ğŸ”§ CeleryæœåŠ¡å¯åŠ¨

### 1. åŸºæœ¬å¯åŠ¨å‘½ä»¤

#### å¯åŠ¨Workerè¿›ç¨‹
```bash
# è¿›å…¥srcç›®å½•
cd src

# å¯åŠ¨é»˜è®¤é˜Ÿåˆ—Worker
celery -A src.celery_app worker --loglevel=info

# å¯åŠ¨æŒ‡å®šé˜Ÿåˆ—Worker
celery -A src.celery_app worker --loglevel=info -Q default

# å¯åŠ¨å¤šä¸ªé˜Ÿåˆ—Worker
celery -A src.celery_app worker --loglevel=info -Q default,web_queue
celery -A src.celery_app worker --loglevel=info -Q secretflow_queue

# åå°å¯åŠ¨Worker
celery -A src.celery_app worker --loglevel=info --detach
```

#### å¯åŠ¨Beatè°ƒåº¦å™¨ï¼ˆå®šæ—¶ä»»åŠ¡ï¼‰
```bash
# å¯åŠ¨Beatè°ƒåº¦å™¨
celery -A src.celery_app beat --loglevel=info

# åå°å¯åŠ¨Beat
celery -A src.celery_app beat --loglevel=info --detach

# ä½¿ç”¨æ•°æ®åº“å­˜å‚¨è°ƒåº¦ä¿¡æ¯
celery -A src.celery_app beat --loglevel=info --scheduler django_celery_beat.schedulers:DatabaseScheduler
```

### 2. å‘½ä»¤è¡Œå‘èµ·ä»»åŠ¡
#### ä½¿ç”¨celery callå‘½ä»¤
```bash
# å‘èµ· hello ä»»åŠ¡
celery -A src.celery_app call tasks.secretflow.hello.hello_task
celery -A src.celery_app call tasks.secretflow.local_test.local_psi_test
celery -A src.celery_app call tasks.secretflow.health_check.health_check_task

export REDIS_URL="redis://localhost:26379/0" & celery -A src.celery_app call tasks.secretflow.health_check.health_check_task


uv run celery -A src.celery_app call tasks.secretflow.execute_task --queue=secretflow_queue --args='[
    "psi-cli-test-001",
    {
        "sf_init_config": {
            "parties": ["alice", "bob"],
            "address": "local"
        },
        "spu_config": {
            "cluster_def": {
                "nodes": [
                    {"party": "alice", "address": "127.0.0.1:12345"},
                    {"party": "bob", "address": "127.0.0.1:12346"}
                ],
                "runtime_config": {
                    "protocol": "SEMI2K",
                    "field": "FM128"
                }
            }
        },
        "task_config": {
            "task_type": "psi",
            "keys": "uid",
            "input_paths": {
                "alice": "/disc/home/beng003/work/secretflow-worker/tests/data/alice.csv",
                "bob": "/disc/home/beng003/work/secretflow-worker/tests/data/bob.csv"
            },
            "output_paths": {
                "alice": "/disc/home/beng003/work/secretflow-worker/tests/data/alice_psi_cli_out.csv",
                "bob": "/disc/home/beng003/work/secretflow-worker/tests/data/bob_psi_cli_out.csv"
            },
            "receiver_party": "alice",
            "protocol": "KKRT_PSI_2PC",
            "sort": true
        }
    }
]'

# æŸ¥çœ‹ä»»åŠ¡ç»“æœ
celery -A src.celery_app result <task_id>
```

### 3. requirements.txt ç”Ÿæˆ
```bash
uv export --format requirements-txt --output-file requirements.txt
```

### 4. Dockerfile

```bash
# ä¸ä½¿ç”¨ç¼“å­˜é‡æ–°æ„å»º
docker build --no-cache -t secretflow-worker .
# æŒ‡å®šæ„å»ºä¸Šä¸‹æ–‡å’ŒDockerfileä½ç½®
docker build -f docker/Dockerfile -t secretflow-worker .
# æŸ¥çœ‹æ„å»ºè¿‡ç¨‹è¯¦ç»†ä¿¡æ¯
docker build -t secretflow-worker . --progress=plain
```

### 5. Docker Compose
```bash
docker compose -f docker/docker-compose.production.yml --env-file .env.production up -d

docker compose -f docker/docker-compose.production.yml --env-file .env.production down

docker compose -f docker/docker-compose.production.yml --env-file .env.production logs -f
```