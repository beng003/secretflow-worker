# SecretFlow Worker 端架构设计

## 概述

本文档介绍 SecretFlow Worker 端的整体架构、核心模块及其职责。Worker 端专注于隐私计算任务的执行，不包含业务逻辑和数据库访问，通过 Celery 接收任务，执行 SecretFlow 计算后返回结果。

## 设计原则

### 1. 单一职责
- **Worker 端仅负责计算任务执行**，不处理业务逻辑
- **不直接访问数据库**，所有数据通过任务参数传递
- **状态通知**而非状态管理，通过 Redis 发布状态事件

### 2. 无状态设计
- 每个任务独立执行，不依赖全局状态
- 任务间无依赖关系，编排逻辑在 Web 端实现
- 支持水平扩展，多个 Worker 实例并行处理任务

### 3. 配置驱动
- 通过环境变量和配置文件管理所有配置
- 支持本地模式和集群模式的灵活切换
- 运行时配置通过任务参数动态传递

## 整体架构

```
┌───────────────────────────────────────────────────────────────┐
│                     SecretFlow Worker 容器                     │
│                                                                │
│  ┌──────────────────────────────────────────────────────────┐ │
│  │                    Celery Worker 层                       │ │
│  │  - 接收任务队列消息                                        │ │
│  │  - 任务生命周期管理                                        │ │
│  │  - 错误处理和重试                                          │ │
│  └─────────────────────┬────────────────────────────────────┘ │
│                        │                                       │
│                        ▼                                       │
│  ┌──────────────────────────────────────────────────────────┐ │
│  │                   任务执行器层                            │ │
│  │  ┌──────────────┐  ┌──────────────┐  ┌────────────────┐ │ │
│  │  │ Celery Tasks │→ │Task Executor │→ │Task Dispatcher │ │ │
│  │  └──────────────┘  └──────────────┘  └────────────────┘ │ │
│  └─────────────────────┬────────────────────────────────────┘ │
│                        │                                       │
│                        ▼                                       │
│  ┌──────────────────────────────────────────────────────────┐ │
│  │                 SecretFlow 计算层                         │ │
│  │  ┌──────────────────┐  ┌──────────────────────────────┐ │ │
│  │  │Cluster Initializer│  │   Device Manager            │ │ │
│  │  └──────────────────┘  └──────────────────────────────┘ │ │
│  │  ┌──────────────────────────────────────────────────────┐ │ │
│  │  │             具体任务实现 (jobs/)                      │ │ │
│  │  │  PSI | LR | XGBoost | Preprocessing | Stats | Eval  │ │ │
│  │  └──────────────────────────────────────────────────────┘ │ │
│  └─────────────────────┬────────────────────────────────────┘ │
│                        │                                       │
│                        ▼                                       │
│  ┌──────────────────────────────────────────────────────────┐ │
│  │                    工具支持层                             │ │
│  │  - 日志管理 (log.py)                                      │ │
│  │  - 异常处理 (exceptions.py)                               │ │
│  │  - 状态通知 (status_notifier.py)                          │ │
│  └──────────────────────────────────────────────────────────┘ │
│                                                                │
└───────────────────────────────────────────────────────────────┘
```

## 核心模块

### 1. Celery应用层 (`src/celery_app.py`)

**职责：**
- 创建和配置 Celery 应用实例
- 自动发现和注册所有任务模块
- 配置任务队列、路由和结果后端

**关键代码：**
```python
# Celery应用配置
celery_app = Celery("secretflow_worker")
celery_app.config_from_object(celery_config)

# 自动导入所有任务模块
def import_all_task_modules():
    for module_name in ["celery_tasks", "hello", "health_check"]:
        importlib.import_module(f"secretflow_task.{module_name}")
    
    # 递归导入jobs包下所有任务
    import_submodules(jobs)
```

### 2. Celery任务层 (`src/secretflow_task/celery_tasks.py`)

**职责：**
- 定义 Celery 任务装饰器
- 实现任务生命周期钩子（开始、成功、失败、重试）
- 封装任务执行逻辑
- 处理新的三级ID体系（task_id、subtask_id、execution_id）

**核心任务：**
```python
@celery_app.task(bind=True, base=SecretFlowTask)
def execute_secretflow_celery_task(self, task_params: Dict[str, Any]) -> Dict[str, Any]:
    """SecretFlow任务执行入口
    
    Args:
        task_params: 任务参数字典，包含：
            - task_id: DAG任务ID
            - subtask_id: 子任务节点ID  
            - execution_id: 执行实例ID
            - sf_init_config: SecretFlow初始化配置
            - spu_config: SPU配置
            - task_config: 任务具体配置
    
    Returns:
        任务执行结果，包含所有三个ID字段
    """
    # 验证参数结构
    _validate_task_params(task_params)
    
    # 提取三个ID字段
    task_id = task_params["task_id"]
    subtask_id = task_params["subtask_id"] 
    execution_id = task_params["execution_id"]
    
    # 发布任务开始状态
    _publish_status(execution_id, "RUNNING", {
        "stage": "task_started",
        "task_id": task_id,
        "subtask_id": subtask_id,
        "execution_id": execution_id
    })
    
    # 调用任务执行器
    result = execute_secretflow_task(
        task_id=task_id,
        subtask_id=subtask_id, 
        execution_id=execution_id,
        sf_init_config=task_params["sf_init_config"],
        spu_config=task_params.get("spu_config"),
        heu_config=task_params.get("heu_config"),
        task_config=task_params["task_config"]
    )
    
    # 更新任务状态包含三个ID
    self.update_state(
        state="SUCCESS",
        meta={
            "task_id": task_id,
            "subtask_id": subtask_id,
            "execution_id": execution_id,
            "result": result
        }
    )
    
    return result
```

**生命周期钩子：**
```python
def on_retry(self, exc, task_id, args, kwargs, einfo):
    """任务重试时触发"""
    task_params = args[0] if args else kwargs.get("task_params", {})
    execution_id = task_params.get("execution_id", "unknown")
    
    _publish_status(execution_id, "RETRY", {
        "stage": "task_retrying",
        "task_id": task_params.get("task_id"),
        "subtask_id": task_params.get("subtask_id"),
        "execution_id": execution_id,
        "retry_count": self.request.retries
    })

def on_failure(self, exc, task_id, args, kwargs, einfo):
    """任务失败时触发"""
    task_params = args[0] if args else kwargs.get("task_params", {})
    execution_id = task_params.get("execution_id", "unknown")
    
    _publish_status(execution_id, "FAILURE", {
        "stage": "task_failed_final",
        "task_id": task_params.get("task_id"),
        "subtask_id": task_params.get("subtask_id"),
        "execution_id": execution_id,
        "error": str(exc)
    })
```

**参数验证：**
```python
def _validate_task_params(task_params: Dict[str, Any]):
    """验证任务参数包含必需的三个ID字段"""
    required_fields = ["task_id", "subtask_id", "execution_id", 
                      "sf_init_config", "task_config"]
    
    for field in required_fields:
        if field not in task_params:
            raise ValueError(f"缺少必需参数: {field}")
    
    # 验证ID字段不为空
    for id_field in ["task_id", "subtask_id", "execution_id"]:
        if not task_params[id_field]:
            raise ValueError(f"ID字段不能为空: {id_field}")
@celery_app.task(
    base=SecretFlowTask,
    name="tasks.secretflow.execute_task",
    bind=True,
    max_retries=3,
    default_retry_delay=60
)
def execute_secretflow_celery_task(
    self,
    task_request_id: str,
    task_params: Dict[str, Any]
) -> Dict[str, Any]:
    """SecretFlow计算任务Celery封装"""
    return execute_secretflow_task(task_request_id, task_params)
```

**生命周期钩子：**
- `on_success`: 任务成功完成，发布成功状态
- `on_failure`: 任务失败，发布失败状态和错误信息
- `on_retry`: 任务重试，记录重试次数
- `after_return`: 任务返回后的清理工作

### 3. 任务执行器 (`src/secretflow_task/task_executor.py`)

**职责：**
- 协调 SecretFlow 集群初始化
- 管理任务执行生命周期
- 收集性能指标和元数据
- 处理三级ID体系的传递和记录

**核心执行函数：**
```python
def execute_secretflow_task(
    task_id: str,           # DAG任务ID
    subtask_id: str,        # 子任务节点ID
    execution_id: str,      # 执行实例ID
    sf_init_config: Dict[str, Any],
    spu_config: Dict[str, Any],
    heu_config: Dict[str, Any],
    task_config: Dict[str, Any],
) -> Dict[str, Any]:
    """执行SecretFlow任务的主入口函数
    
    所有日志、状态通知、性能指标都会包含三个ID字段用于精确追踪
    """
    
    logger.info(
        f"开始执行SecretFlow任务: task_id={task_id}, "
        f"subtask_id={subtask_id}, execution_id={execution_id}"
    )
    
    # 1. 集群初始化（包含ID追踪）
    cluster_initializer = ClusterInitializer(execution_id)
    cluster_initializer.initialize_cluster(sf_init_config)
    
    # 2. 设备管理（包含ID追踪）
    device_manager = DeviceManager(execution_id)
    devices = device_manager.initialize_devices(
        sf_init_config["parties"], spu_config, heu_config
    )
    
    # 3. 任务分发执行
    result = TaskDispatcher.dispatch(
        task_config, devices, 
        task_id=task_id,
        subtask_id=subtask_id, 
        execution_id=execution_id
    )
    
    # 4. 收集元数据（包含所有ID）
    task_metadata = {
        "task_id": task_id,
        "subtask_id": subtask_id,
        "execution_id": execution_id,
        "task_type": task_config.get("task_type"),
        "started_at": start_time.isoformat(),
        "completed_at": datetime.now().isoformat(),
        "devices_used": list(devices.keys())
    }
    
    return {
        "status": "success",
        "result": result,
        "performance_metrics": performance_metrics,
        "task_metadata": task_metadata
    }
```

**职责：**
- 统一的任务执行入口
- SecretFlow 集群初始化和管理
- 设备（PYU/SPU）初始化和清理
- 性能指标收集

**执行流程：**
```python
def execute_secretflow_task(task_request_id, task_params):
    # 1. 集群初始化
    cluster_initializer.initialize_cluster(sf_init_config)
    
    # 2. 设备初始化
    device_manager.initialize_devices(parties, spu_config)
    
    # 3. 任务分发执行
    result = TaskDispatcher.dispatch(task_type, devices, task_config)
    
    # 4. 资源清理
    device_manager.cleanup_devices()
    cluster_initializer.shutdown_cluster()
    
    return result
```

### 4. 任务分发器 (`src/secretflow_task/task_dispatcher.py`)

**职责：**
- 根据任务类型路由到具体实现
- 管理任务注册和发现
- 传递执行上下文和ID信息

**核心分发逻辑：**
```python
class TaskDispatcher:
    @staticmethod
    def dispatch(task_config: Dict[str, Any], devices: Dict[str, Any], 
                task_id: str, subtask_id: str, execution_id: str) -> Dict[str, Any]:
        """分发任务到具体实现
        
        Args:
            task_config: 任务配置
            devices: SecretFlow设备字典
            task_id: DAG任务ID
            subtask_id: 子任务节点ID
            execution_id: 执行实例ID
        """
        task_type = task_config["task_type"]
        
        if task_type not in TaskDispatcher._registered_tasks:
            raise TaskTypeNotFoundError(f"未知任务类型: {task_type}")
        
        task_func = TaskDispatcher._registered_tasks[task_type]
        
        logger.info(
            f"开始执行任务: task_type='{task_type}', "
            f"task_id={task_id}, subtask_id={subtask_id}, execution_id={execution_id}"
        )
        
        # 调用具体任务实现，传递所有ID信息
        result = task_func(
            devices, task_config,
            task_id=task_id,
            subtask_id=subtask_id, 
            execution_id=execution_id
        )
        
        logger.info(f"任务执行成功: task_type='{task_type}'")
        return result

    @classmethod
    def register_task(cls, task_type: str):
        """注册任务类型装饰器"""
        def decorator(func):
            cls._registered_tasks[task_type] = func
            logger.info(f"成功注册任务类型: '{task_type}' -> {func.__name__}")
            return func
        return decorator
```

**职责：**
- 维护任务类型到执行函数的注册表
- 提供装饰器注册任务
- 根据任务类型分发到对应的执行函数

**装饰器模式：**
```python
class TaskDispatcher:
    TASK_REGISTRY: Dict[str, Callable] = {}
    
    @classmethod
    def register_task(cls, task_type: str):
        """注册任务装饰器"""
        def decorator(func: Callable):
            cls.TASK_REGISTRY[task_type] = func
            return func
        return decorator
    
    @classmethod
    def dispatch(cls, task_type: str, devices, task_config):
        """分发任务到对应的执行函数"""
        task_func = cls.TASK_REGISTRY[task_type]
        return task_func(devices, task_config)
```

### 5. 集群初始化器 (`src/secretflow_task/cluster_initializer.py`)

**职责：**
- 初始化 SecretFlow 运行环境
- 配置 Ray 集群连接
- 设置运行时环境和日志
- 为执行实例提供唯一的集群会话

**初始化逻辑：**
```python
class ClusterInitializer:
    def __init__(self, execution_id: str):
        self.execution_id = execution_id
        self.cluster_config = None
    
    def initialize_cluster(self, sf_init_config: Dict[str, Any]):
        """初始化SecretFlow集群
        
        为每个execution_id创建独立的集群会话
        """
        logger.info(
            f"开始初始化SecretFlow集群: execution_id={self.execution_id}"
        )
        
        # 配置运行时环境
        runtime_env = {
            "env_vars": {
                "PYTHONPATH": "/app/src",
                "EXECUTION_ID": self.execution_id  # 传递执行ID到Ray workers
            }
        }
        
        # 根据配置初始化不同模式
        if sf_init_config.get("address") == "local":
            self._init_local_cluster(sf_init_config, runtime_env)
        else:
            self._init_remote_cluster(sf_init_config, runtime_env)
    
    def _init_local_cluster(self, config, runtime_env):
        """本地模式初始化"""
        sf.init(
            parties=config["parties"],
            address="local",
            runtime_env=runtime_env,
            log_to_driver=True
        )
        
        logger.info(
            f"本地集群初始化完成: execution_id={self.execution_id}, "
            f"parties={config['parties']}"
        )
```

**职责：**
- SecretFlow 集群的初始化和关闭
- Ray 运行时环境配置
- 集群状态管理

**关键功能：**
```python
def initialize_cluster(self, sf_init_config):
    # 配置Ray运行时环境，确保worker能找到项目模块
    if 'runtime_env' not in sf_init_config:
        sf_init_config['runtime_env'] = {}
    
    # 设置PYTHONPATH
    sf_init_config['runtime_env']['env_vars']['PYTHONPATH'] = '/app/src'
    
    # 初始化SecretFlow
    sf.init(**sf_init_config)
```

### 6. 设备管理器 (`src/secretflow_task/device_manager.py`)

**职责：**
- PYU（Python执行单元）设备创建
- SPU（安全处理单元）设备创建  
- 设备资源清理
- 为每个执行实例管理独立的设备会话

**设备创建：**
```python
class DeviceManager:
    def __init__(self, execution_id: str):
        self.execution_id = execution_id
        self._devices = {}
    
    def initialize_devices(self, parties, spu_config, heu_config=None):
        """初始化计算设备
        
        为当前execution_id创建独立的设备实例
        """
        logger.info(
            f"开始初始化设备: execution_id={self.execution_id}, parties={parties}"
        )
        
        # 创建PYU设备
        for party in parties:
            self._devices[party] = sf.PYU(party)
            logger.debug(f"创建PYU设备: {party} (execution_id={self.execution_id})")
        
        # 创建SPU设备（如需要）
        if spu_config:
            self._devices["spu"] = sf.SPU(spu_config["cluster_def"])
            logger.debug(f"创建SPU设备 (execution_id={self.execution_id})")
        
        # 创建HEU设备（如需要）
        if heu_config:
            self._devices["heu"] = sf.HEU(heu_config)
            logger.debug(f"创建HEU设备 (execution_id={self.execution_id})")
        
        logger.info(
            f"设备初始化完成: execution_id={self.execution_id}, "
            f"devices={list(self._devices.keys())}"
        )
        
        return self._devices
    
    def cleanup_devices(self):
        """清理设备资源"""
        logger.info(f"开始清理设备资源: execution_id={self.execution_id}")
        
        for device_name, device in self._devices.items():
            try:
                if hasattr(device, 'shutdown'):
                    device.shutdown()
                logger.info(f"成功关闭设备: {device_name}")
            except Exception as e:
                logger.warning(f"关闭设备失败 {device_name}: {e}")
        
        self._devices.clear()
        logger.info("所有设备已清理完成")
```

**职责：**
- PYU（Python执行单元）设备创建
- SPU（安全处理单元）设备创建
- 设备资源清理

**设备创建：**
```python
def initialize_devices(self, parties, spu_config):
    # 创建PYU设备
    for party in parties:
        self._devices[party] = sf.PYU(party)
    
    # 创建SPU设备（如需要）
    if spu_config:
        self._devices["spu"] = sf.SPU(spu_config["cluster_def"])
```

### 7. 具体任务实现 (`src/secretflow_task/jobs/`)

**目录结构：**
```
jobs/
├── psi_task.py              # PSI隐私求交
├── linear/                  # 线性模型
│   ├── ss_lr_task.py       # 联邦逻辑回归
│   └── ss_lr_predict_task.py # 逻辑回归预测
├── boost/                   # 集成学习
│   ├── ss_xgb_task.py      # 联邦XGBoost
│   └── ss_xgb_predict_task.py # XGBoost预测
├── preprocessing/           # 数据预处理
│   ├── scaler/             # 标准化/归一化
│   ├── encoder/            # 编码
│   ├── binning/            # 分箱
│   └── fillna/             # 缺失值填充
├── stats/                   # 统计分析
└── evaluation/             # 模型评估
```

**任务实现模式：**
```python
@TaskDispatcher.register_task("psi")
def execute_psi(devices, task_config, task_id, subtask_id, execution_id):
    """PSI隐私求交任务
    
    Args:
        devices: SecretFlow设备字典
        task_config: PSI任务配置
        task_id: DAG任务ID
        subtask_id: 子任务节点ID  
        execution_id: 执行实例ID
    
    Returns:
        PSI执行结果，包含交集统计和输出路径
    """
    
    logger.info(
        f"开始执行PSI任务: task_id={task_id}, "
        f"subtask_id={subtask_id}, execution_id={execution_id}"
    )
    
    # 1. 参数解析
    keys = task_config["keys"]
    input_paths = task_config["input_paths"] 
    output_paths = task_config["output_paths"]
    protocol = task_config.get("protocol", "KKRT_PSI_2PC")
    
    # 2. 执行PSI计算
    spu = devices["spu"]
    result = spu.psi_csv(
        keys=keys,
        input_path=input_paths,
        output_path=output_paths,
        receiver=task_config["receiver"],
        protocol=protocol
    )
    
    # 3. 记录执行结果
    logger.info(
        f"PSI任务执行成功: execution_id={execution_id}, "
        f"intersection_count={result['intersection_count']}"
    )
    
    return {
        "intersection_count": result["intersection_count"],
        "output_paths": output_paths,
        "protocol": protocol,
        "parties": list(keys.keys())
    }
```

**目录结构：**
```
jobs/
├── psi_task.py              # PSI隐私求交
├── linear/                  # 线性模型
│   └── ss_lr_task.py       
├── boost/                   # 集成学习
│   └── ss_xgb_task.py      
├── preprocessing/           # 数据预处理
│   ├── scaler/             # 标准化/归一化
│   ├── encoder/            # 编码
│   ├── binning/            # 分箱
│   └── fillna/             # 缺失值填充
├── stats/                   # 统计分析
│   ├── table_statistics_task.py
│   ├── pearson_correlation_task.py
│   └── vif_task.py
└── evaluation/              # 模型评估
    ├── biclassification_eval_task.py
    └── regression_eval_task.py
```

**任务实现模式：**
```python
@TaskDispatcher.register_task("task_type")
def execute_task(devices: Dict[str, PYU], task_config: Dict) -> Dict:
    """
    任务执行函数
    
    Args:
        devices: 设备字典 {party: PYU, "spu": SPU}
        task_config: 任务配置参数
    
    Returns:
        任务执行结果
    """
    # 1. 参数验证
    _validate_config(task_config)
    
    # 2. 数据加载
    data = load_data(devices, task_config)
    
    # 3. SecretFlow计算
    result = perform_computation(data, devices)
    
    # 4. 结果处理
    return format_result(result)
```

## 工具支持层

### 1. 日志管理 (`src/utils/log.py`)

**功能：**
- 结构化日志输出
- 日志级别控制
- 文件和控制台双输出
- 进程ID和时间戳标记

### 2. 异常处理 (`src/utils/exceptions.py`)

**自定义异常：**
- `SecretFlowTaskError`: 任务执行基础异常
- `ClusterInitializationError`: 集群初始化异常
- `DeviceInitializationError`: 设备初始化异常
- `TaskExecutionError`: 任务执行异常
- `ParameterValidationError`: 参数验证异常
- `ResultSaveError`: 结果保存异常

### 3. 状态通知 (`src/utils/status_notifier.py`)

**职责：**
- 向 Redis 发布任务状态事件
- 支持跨容器的状态同步
- 使用execution_id作为主要标识符
- 包含完整的三级ID信息

**状态发布：**
```python
def _publish_status(execution_id: str, status: str, extra_data: Dict = None):
    """发布任务状态到Redis
    
    Args:
        execution_id: 执行实例ID（主要标识符）
        status: 任务状态（RUNNING, SUCCESS, FAILURE, RETRY等）
        extra_data: 额外数据，应包含task_id和subtask_id
    """
    try:
        # 构建事件数据
        event_data = {
            "execution_id": execution_id,
            "status": status,
            "timestamp": datetime.now().isoformat(),
            "worker_id": os.getenv("WORKER_HOSTNAME", "unknown"),
        }
        
        # 添加三级ID信息
        if extra_data:
            event_data.update(extra_data)
            # 确保包含所有ID字段
            if "task_id" not in event_data:
                logger.warning(f"缺少task_id字段: execution_id={execution_id}")
            if "subtask_id" not in event_data:
                logger.warning(f"缺少subtask_id字段: execution_id={execution_id}")
        
        # 向Redis发布事件
        redis_client = get_redis_client()
        channel = f"task_status:{execution_id}"
        
        redis_client.publish(channel, json.dumps(event_data))
        
        # 同时发布到通用频道（兼容性）
        redis_client.publish("task_status", json.dumps(event_data))
        
        logger.debug(
            f"状态事件已发布: execution_id={execution_id}, "
            f"status={status}, channel={channel}"
        )
        
    except Exception as e:
        logger.error(f"发布状态失败: execution_id={execution_id}, error={e}")
```

**功能：**
- 通过Redis发布任务状态事件
- 双重保障：发布订阅 + 消息队列
- 状态事件标准化格式

## 任务执行流程

```
┌─────────────────────────────────────────────────────────────────┐
│ 1. 接收任务                                                      │
│    - Celery Worker从Redis队列拉取任务                            │
│    - 解析task_request_id和task_params                           │
└────────────────────┬────────────────────────────────────────────┘
                     │
                     ▼
┌─────────────────────────────────────────────────────────────────┐
│ 2. 任务前置处理                                                   │
│    - 记录任务开始时间                                             │
│    - 发布RUNNING状态到Redis                                       │
│    - 提取sf_init_config、spu_config、task_config                │
└────────────────────┬────────────────────────────────────────────┘
                     │
                     ▼
┌─────────────────────────────────────────────────────────────────┐
│ 3. 集群初始化                                                     │
│    - 配置Ray运行时环境(PYTHONPATH)                                │
│    - 调用sf.init()初始化SecretFlow集群                           │
│    - 记录集群初始化耗时                                           │
└────────────────────┬────────────────────────────────────────────┘
                     │
                     ▼
┌─────────────────────────────────────────────────────────────────┐
│ 4. 设备初始化                                                     │
│    - 为每个参与方创建PYU设备                                       │
│    - 创建SPU设备（如需密态计算）                                   │
│    - 记录设备初始化耗时                                           │
└────────────────────┬────────────────────────────────────────────┘
                     │
                     ▼
┌─────────────────────────────────────────────────────────────────┐
│ 5. 任务分发执行                                                   │
│    - TaskDispatcher.dispatch(task_type, devices, task_config)   │
│    - 参数验证                                                     │
│    - 数据加载和处理                                               │
│    - SecretFlow计算                                              │
│    - 结果保存                                                     │
│    - 记录算法执行耗时                                             │
└────────────────────┬────────────────────────────────────────────┘
                     │
                     ▼
┌─────────────────────────────────────────────────────────────────┐
│ 6. 资源清理                                                       │
│    - device_manager.cleanup_devices()                           │
│    - cluster_initializer.shutdown_cluster()                     │
│    - sf.shutdown()                                              │
└────────────────────┬────────────────────────────────────────────┘
                     │
                     ▼
┌─────────────────────────────────────────────────────────────────┐
│ 7. 结果返回                                                       │
│    - 构建完整响应（result + performance_metrics + metadata）      │
│    - 发布SUCCESS状态到Redis                                       │
│    - 返回结果给Celery                                             │
└─────────────────────────────────────────────────────────────────┘
```

## 配置管理

### 1. 环境变量配置 (`src/config/settings.py`)

```python
class Settings:
    # Redis配置
    redis_url: str = os.getenv("REDIS_URL", "redis://localhost:6379/0")
    
    # Celery配置
    celery_broker_url: str = redis_url
    celery_result_backend: str = redis_url
    
    # SecretFlow配置
    secretflow_parties: str = os.getenv("SECRETFLOW_PARTIES", "alice,bob")
    secretflow_address: str = os.getenv("SECRETFLOW_ADDRESS", "local")
    
    # 日志配置
    log_level: str = os.getenv("LOG_LEVEL", "INFO")
    log_file: str = os.getenv("LOG_FILE", "/app/logs/worker.log")
```

### 2. Celery配置 (`src/config/celery_config.py`)

```python
# 任务配置
task_serializer = "json"
result_serializer = "json"
accept_content = ["json"]
task_time_limit = 3600
task_soft_time_limit = 3000

# 队列配置
task_routes = {
    "tasks.secretflow.*": {"queue": "secretflow_queue"}
}

# 结果配置
result_expires = 86400
result_backend_transport_options = {
    "master_name": "mymaster"
}
```

## 扩展性设计

### 1. 添加新任务类型

1. 在 `src/secretflow_task/jobs/` 下创建任务文件
2. 使用 `@TaskDispatcher.register_task()` 装饰器注册
3. 实现任务逻辑，返回标准格式结果

### 2. 支持新的SecretFlow功能

1. 在相应目录下添加任务实现
2. 遵循现有的参数验证和错误处理模式
3. 使用设备管理器获取PYU/SPU设备
4. 返回包含详细信息的结果字典

### 3. 水平扩展

- 启动多个Worker容器实例
- 共享Redis消息队列
- 任务自动负载均衡
- 支持不同节点部署不同参与方

## 性能优化

### 1. 集群复用
- 单个Worker进程内集群初始化一次
- 多个任务共享同一集群实例
- 减少集群启动开销

### 2. 设备缓存
- 任务级别的设备生命周期
- 避免频繁创建销毁设备
- 及时清理释放资源

### 3. 并发控制
- Celery Worker并发数配置
- 任务优先级队列
- 资源限制和超时控制

## 监控和日志

### 1. 结构化日志
- 进程ID标识
- 时间戳精确到毫秒
- 关键操作耗时记录
- 错误堆栈完整输出

### 2. 性能指标
- 集群初始化时间
- 设备初始化时间
- 算法执行时间
- 各阶段占比分析

### 3. 状态事件
- 任务开始（RUNNING）
- 任务成功（SUCCESS）
- 任务失败（FAILURE）
- 任务重试（RETRY）

## 安全性考虑

### 1. 数据隔离
- 不同任务数据独立处理
- 临时文件及时清理
- 敏感信息不落盘

### 2. 资源限制
- 任务执行时间限制
- 内存使用监控
- CPU使用率控制

### 3. 错误处理
- 异常信息脱敏
- 错误重试机制
- 失败任务隔离

## 总结

SecretFlow Worker 端采用分层架构，职责清晰：
- **Celery层**：任务队列和生命周期管理
- **执行器层**：统一的任务执行流程
- **计算层**：SecretFlow集群和设备管理
- **任务层**：具体的隐私计算算法实现
- **工具层**：日志、异常、状态通知等支持

这种设计使得Worker端专注于计算任务执行，易于扩展和维护，支持水平扩展以处理高并发任务请求。
