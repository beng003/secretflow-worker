# Redis消息队列跨容器任务状态监听系统设计

## 项目概述

在分布式容器架构（FastAPI+Celery容器 与 SecretFlow Worker容器）中，实现可靠的任务状态跨容器同步机制。采用Redis消息队列 + 发布订阅双重保障的方案，确保任务状态变更能够及时、可靠地从Worker容器传递到Web容器并更新数据库。

## 架构设计

### 整体架构图
```
┌─────────────────────────┐    Redis消息    ┌─────────────────────────┐
│   SecretFlow Worker     │ ────────────→   │   FastAPI Web容器       │
│   容器                  │    发布状态     │                         │
│                         │                 │                         │
│ ┌─────────────────────┐ │                 │ ┌─────────────────────┐ │
│ │   Celery任务        │ │                 │ │  状态监听服务       │ │
│ │   (纯计算)          │ │                 │ │  TaskStatusListener │ │
│ │                     │ │                 │ │                     │ │
│ │ _publish_task_event │ │                 │ │ _handle_status_event│ │
│ └─────────────────────┘ │                 │ └─────────────────────┘ │
└─────────────────────────┘                 │            │            │
                                            │            ▼            │
                                            │ ┌─────────────────────┐ │
                                            │ │  TaskStatusService  │ │
                                            │ │  (数据库更新)       │ │
                                            │ └─────────────────────┘ │
                                            └─────────────────────────┘
```

### 核心组件

#### 1. Worker容器端 (secretflow-worker)
- **任务状态通知器** (`_publish_task_event`)
- **Redis连接管理**
- **状态事件序列化**

#### 2. Web容器端 (web)
- **状态监听服务** (`TaskStatusListener`)
- **状态处理服务** (`TaskStatusService`)  
- **数据库更新逻辑**

#### 3. 消息传输层 (Redis)
- **发布订阅频道**: `task_status_events`
- **消息队列**: `task_status_queue` (防丢失)
- **消息格式标准化**

## 详细设计

### 消息格式规范

```json
{
  "task_request_id": "uuid-string",
  "status": "RUNNING|SUCCESS|FAILURE|RETRY",
  "timestamp": "2026-01-03T16:23:45.123456Z",
  "data": {
    "started_at": "timestamp",
    "cpu_usage": 45.2,
    "memory_usage": 62.1,
    "error": "error_message",
    "result": {}
  },
  "worker_container": "secretflow-worker",
  "task_name": "tasks.web.system.analyze_resources"
}
```

### Worker容器实现

#### 任务状态通知工具 (`src/tasks/utils/status_notifier.py`)

```python
import redis
import json
from datetime import datetime
from typing import Dict, Any
from log.log import logger
from settings.config import settings

def _publish_task_event(task_request_id: str, status: str, data: Dict[str, Any], task_name: str = None):
    """发布跨容器任务状态事件"""
    redis_client = redis.Redis.from_url(settings.redis_url)
    
    event = {
        "task_request_id": task_request_id,
        "status": status,
        "timestamp": datetime.now().isoformat(),
        "data": data,
        "worker_container": settings.WORKER_CONTAINER_ID,
        "task_name": task_name
    }
    
    try:
        # 双重保障：发布订阅 + 队列
        redis_client.publish("task_status_events", json.dumps(event))
        redis_client.lpush("task_status_queue", json.dumps(event))
        
        logger.debug(f"任务状态事件已发布: {task_request_id} -> {status}")
        
    except Exception as e:
        logger.error(f"发布任务状态事件失败: {e}", extra={"event": event})
```

#### 任务集成示例

```python
# src/tasks/web/system.py 修改
from tasks.utils.status_notifier import _publish_task_event

@celery_app.task(base=SystemTask, name="tasks.web.system.analyze_resources")
def analyze_system_resources(task_request_id: str, analysis_config: dict = None) -> dict[str, Any]:
    """系统资源分析任务 - 支持状态通知"""
    
    try:
        # 发送开始状态
        _publish_task_event(
            task_request_id=task_request_id,
            status="RUNNING",
            data={"started_at": datetime.now().isoformat()},
            task_name="tasks.web.system.analyze_resources"
        )
        
        # 执行纯计算逻辑
        result = {
            "cpu_usage": analyze_cpu_usage(),
            "memory_usage": analyze_memory_usage(),
            "disk_usage": analyze_disk_usage(),
            "analysis_time": datetime.now().isoformat()
        }
        
        # 发送成功状态
        _publish_task_event(
            task_request_id=task_request_id,
            status="SUCCESS",
            data=result,
            task_name="tasks.web.system.analyze_resources"
        )
        
        return result
        
    except Exception as e:
        # 发送失败状态
        _publish_task_event(
            task_request_id=task_request_id,
            status="FAILURE",
            data={"error": str(e), "error_type": type(e).__name__},
            task_name="tasks.web.system.analyze_resources"
        )
        raise
```

### Web容器实现

#### 状态监听服务 (`src/services/task_status_listener.py`)

```python
import asyncio
import aioredis
import json
from typing import Dict, Any
from log.log import logger
from settings.config import settings
from services.task_status_service import TaskStatusService

class TaskStatusListener:
    """跨容器任务状态监听器"""
    
    def __init__(self):
        self.redis = None
        self.running = False
        self.task_status_service = TaskStatusService()
        
    async def start_listening(self):
        """启动状态监听服务"""
        self.redis = aioredis.from_url(settings.redis_url)
        self.running = True
        
        logger.info("任务状态监听器启动中...")
        
        # 并行监听发布/订阅和队列
        await asyncio.gather(
            self._listen_pubsub(),
            self._process_status_queue(),
        )
    
    async def stop_listening(self):
        """停止监听服务"""
        self.running = False
        if self.redis:
            await self.redis.close()
        logger.info("任务状态监听器已停止")
    
    async def _listen_pubsub(self):
        """监听Redis发布/订阅频道"""
        pubsub = self.redis.pubsub()
        await pubsub.subscribe("task_status_events")
        
        logger.info("开始监听任务状态发布订阅频道")
        
        async for message in pubsub.listen():
            if message["type"] == "message":
                try:
                    event_data = json.loads(message["data"])
                    await self._handle_status_event(event_data)
                except Exception as e:
                    logger.error(f"处理发布订阅消息异常: {e}")
    
    async def _process_status_queue(self):
        """处理队列中的状态消息（确保不丢失）"""
        logger.info("开始处理任务状态队列")
        
        while self.running:
            try:
                # 从队列右端弹出消息，阻塞等待5秒
                message = await self.redis.brpop("task_status_queue", timeout=5)
                if message:
                    event_data = json.loads(message[1])
                    await self._handle_status_event(event_data)
                    
            except asyncio.TimeoutError:
                continue
            except Exception as e:
                logger.error(f"处理状态队列异常: {e}")
                await asyncio.sleep(1)
    
    async def _handle_status_event(self, event: Dict[str, Any]):
        """处理任务状态事件"""
        try:
            task_request_id = event["task_request_id"]
            status = event["status"]
            data = event["data"]
            task_name = event.get("task_name")
            worker_container = event.get("worker_container")
            
            # 调用Service层更新数据库
            await self.task_status_service.update_task_status(
                task_request_id=task_request_id,
                status=status,
                result_data=data,
                task_name=task_name,
                worker_source=worker_container,
                updated_at=datetime.now()
            )
            
            logger.info(f"任务状态已更新: {task_request_id} -> {status}")
            
        except Exception as e:
            logger.error(f"处理任务状态事件失败: {e}", extra={"event": event})
            # 不抛出异常，确保监听器继续运行
```

#### 状态更新服务 (`src/services/task_status_service.py`)

```python
from datetime import datetime
from typing import Dict, Any, Optional
from repositories.task_request_repository import TaskRequestRepository
from repositories.task_log_repository import TaskLogRepository
from log.log import logger

class TaskStatusService:
    """任务状态更新服务"""
    
    def __init__(self):
        self.task_request_repo = TaskRequestRepository()
        self.task_log_repo = TaskLogRepository()
    
    async def update_task_status(
        self,
        task_request_id: str,
        status: str,
        result_data: Dict[str, Any] = None,
        task_name: Optional[str] = None,
        worker_source: Optional[str] = None,
        updated_at: datetime = None
    ):
        """更新任务状态到数据库"""
        
        if updated_at is None:
            updated_at = datetime.now()
            
        try:
            # 更新任务请求状态
            await self.task_request_repo.update_status(
                task_request_id=task_request_id,
                status=status,
                updated_at=updated_at
            )
            
            # 如果有结果数据，更新结果
            if result_data and status == "SUCCESS":
                await self.task_request_repo.update_result(
                    task_request_id=task_request_id,
                    result=result_data
                )
            
            # 记录任务日志
            await self.task_log_repo.create({
                "task_request_id": task_request_id,
                "status": status,
                "message": self._generate_log_message(status, result_data),
                "task_name": task_name,
                "worker_source": worker_source,
                "created_at": updated_at
            })
            
            logger.info(f"任务状态数据库更新完成: {task_request_id} -> {status}")
            
        except Exception as e:
            logger.error(f"任务状态数据库更新失败: {e}", extra={
                "task_request_id": task_request_id,
                "status": status,
                "result_data": result_data
            })
            raise
    
    def _generate_log_message(self, status: str, result_data: Dict[str, Any] = None) -> str:
        """生成日志消息"""
        if status == "RUNNING":
            return "任务开始执行"
        elif status == "SUCCESS":
            return f"任务执行成功，耗时: {result_data.get('execution_time', 'N/A')}"
        elif status == "FAILURE":
            error = result_data.get('error', 'Unknown error') if result_data else 'Unknown error'
            return f"任务执行失败: {error}"
        elif status == "RETRY":
            return "任务重试中"
        else:
            return f"任务状态变更: {status}"
```

### 应用集成

#### 启动时加载监听器 (`src/core/init_app.py`)

```python
import asyncio
from services.task_status_listener import TaskStatusListener

# 全局监听器实例
task_status_listener = None

async def setup_task_status_listener():
    """设置任务状态监听器"""
    global task_status_listener
    
    if settings.ENABLE_TASK_STATUS_LISTENER:
        task_status_listener = TaskStatusListener()
        
        # 在后台启动监听
        asyncio.create_task(task_status_listener.start_listening())
        logger.info("跨容器任务状态监听器已启动")

async def shutdown_task_status_listener():
    """关闭任务状态监听器"""
    global task_status_listener
    
    if task_status_listener:
        await task_status_listener.stop_listening()
        logger.info("任务状态监听器已关闭")

# 在应用启动和关闭时调用
def register_startup_event(app):
    app.add_event_handler("startup", setup_task_status_listener)
    app.add_event_handler("shutdown", shutdown_task_status_listener)
```

### 配置与环境变量

#### Docker Compose 配置

```yaml
# docker/docker-compose.yml 修改
services:
  web:
    environment:
      - ENABLE_TASK_STATUS_LISTENER=true
      - REDIS_URL=redis://redis:6379/0
      
  secretflow-worker:
    environment:
      - WORKER_CONTAINER_ID=secretflow-worker
      - REDIS_URL=redis://redis:6379/0
      - ENABLE_STATUS_NOTIFICATIONS=true
```

#### 应用配置 (`src/settings/config.py`)

```python
# 新增配置项
ENABLE_TASK_STATUS_LISTENER: bool = True
WORKER_CONTAINER_ID: str = "secretflow-worker"
TASK_STATUS_REDIS_CHANNEL: str = "task_status_events"
TASK_STATUS_QUEUE_NAME: str = "task_status_queue"
```

## 实现任务列表

### Phase 1: 基础设施搭建 (预计2天)

#### 1.1 创建核心服务文件
- [ ] **创建 `src/tasks/utils/status_notifier.py`**
  - 实现 `_publish_task_event` 函数
  - Redis连接管理
  - 错误处理和日志记录
  - 消息序列化和标准化

- [ ] **创建 `src/services/task_status_listener.py`**
  - 实现 `TaskStatusListener` 类
  - 发布订阅监听 `_listen_pubsub`
  - 队列处理 `_process_status_queue`
  - 事件处理 `_handle_status_event`

- [ ] **创建 `src/services/task_status_service.py`**
  - 实现 `TaskStatusService` 类
  - 数据库状态更新逻辑
  - 任务日志记录
  - 错误处理机制

#### 1.2 数据库模型扩展
- [ ] **扩展任务请求模型** (`src/models/task.py`)
  - 添加 `worker_source` 字段
  - 添加 `last_status_update` 时间戳
  - 添加状态变更历史支持

- [ ] **创建任务日志模型** (如不存在)
  - 状态变更日志表设计
  - 索引优化配置
  - 数据保留策略

#### 1.3 配置系统更新
- [ ] **更新应用配置** (`src/settings/config.py`)
  - 添加监听器开关配置
  - Redis频道和队列名配置
  - Worker容器标识配置

- [ ] **更新Docker配置** (`docker/docker-compose.yml`)
  - 添加环境变量
  - 确保Redis连接配置
  - Worker容器标识设置

### Phase 2: 任务集成改造 (预计3天)

#### 2.1 Worker端任务改造
- [ ] **改造 System 任务** (`src/tasks/web/system.py`)
  - `analyze_cleanup_statistics` 添加状态通知
  - `analyze_file_cleanup_patterns` 添加状态通知
  - `analyze_system_resources` 添加状态通知

- [ ] **改造 Certificate 任务** (`src/tasks/web/certificate.py`)
  - `validate_certificate_batch` 添加状态通知
  - `encrypt_certificate_data` 添加状态通知
  - `decrypt_certificate_data` 添加状态通知

- [ ] **改造 Diagnostics 任务** (`src/tasks/web/diagnostics.py`)
  - `analyze_network_performance` 添加状态通知
  - `analyze_connectivity_matrix` 添加状态通知
  - `analyze_ssl_certificates` 添加状态通知

#### 2.2 状态通知标准化
- [ ] **统一状态事件格式**
  - 制定消息格式规范文档
  - 实现消息验证机制
  - 添加消息版本控制

- [ ] **错误处理优化**
  - 通知失败重试机制
  - 网络异常处理
  - 消息丢失检测与恢复

### Phase 3: Web端监听系统 (预计2天)

#### 3.1 监听器集成
- [ ] **应用启动集成** (`src/core/init_app.py`)
  - 监听器启动逻辑
  - 优雅关闭处理
  - 健康检查集成

- [ ] **Service层更新**
  - Repository层状态更新方法
  - 事务处理优化
  - 并发安全保障

#### 3.2 监控与日志
- [ ] **监听器监控指标**
  - 消息处理成功率统计
  - 处理延迟监控
  - 错误率告警

- [ ] **日志系统优化**
  - 结构化日志输出
  - 状态变更审计日志
  - 性能分析日志

### Phase 4: 测试与优化 (预计3天)

#### 4.1 单元测试
- [ ] **状态通知器测试** (`tests/tasks/utils/test_status_notifier.py`)
  - Redis连接测试
  - 消息发布测试
  - 异常处理测试

- [ ] **监听器测试** (`tests/services/test_task_status_listener.py`)
  - 消息接收测试
  - 状态处理测试
  - 错误恢复测试

- [ ] **Service层测试** (`tests/services/test_task_status_service.py`)
  - 数据库更新测试
  - 事务处理测试
  - 并发安全测试

#### 4.2 集成测试
- [ ] **端到端测试** (`tests/integration/test_cross_container_status.py`)
  - Worker → Web 状态流转测试
  - 多任务并发测试
  - 容器重启恢复测试

- [ ] **性能测试**
  - 高并发状态更新测试
  - 消息处理延迟测试
  - Redis性能压力测试

#### 4.3 部署验证
- [ ] **Docker环境测试**
  - 多容器通信测试
  - 网络隔离测试
  - 容器故障恢复测试

- [ ] **生产环境准备**
  - 监控告警配置
  - 日志收集配置
  - 性能调优验证

### Phase 5: 文档与维护 (预计1天)

#### 5.1 技术文档
- [ ] **API文档更新**
  - 状态更新接口文档
  - 配置参数说明文档
  - 故障排除指南

- [ ] **运维文档**
  - 部署配置指南
  - 监控指标说明
  - 常见问题解决方案

#### 5.2 代码优化
- [ ] **代码审查与重构**
  - 代码规范检查
  - 性能优化点识别
  - 安全漏洞排查

- [ ] **版本发布准备**
  - 变更日志编写
  - 版本兼容性测试
  - 回滚方案准备

## 风险评估与应对

### 技术风险
1. **Redis性能瓶颈**
   - 风险: 高频状态更新可能导致Redis压力过大
   - 应对: 消息批处理、连接池优化、Redis集群

2. **消息丢失风险**
   - 风险: 网络异常或Redis故障导致状态更新丢失
   - 应对: 双重保障机制（发布订阅+队列）、消息持久化

3. **跨容器网络延迟**
   - 风险: 容器间通信延迟影响实时性
   - 应对: 异步处理、超时重试、性能监控

### 业务风险
1. **状态不一致**
   - 风险: Worker和Web容器状态不同步
   - 应对: 状态校验机制、定期同步任务

2. **监听器故障**
   - 风险: 监听器崩溃导致状态更新中断
   - 应对: 自动重启、健康检查、故障告警

## 成功指标

### 功能指标
- [ ] 状态同步成功率 > 99.9%
- [ ] 状态更新延迟 < 1秒
- [ ] 消息丢失率 < 0.01%

### 性能指标  
- [ ] 支持 1000+ 并发任务状态更新
- [ ] Redis CPU使用率 < 80%
- [ ] 监听器内存占用 < 100MB

### 可靠性指标
- [ ] 容器重启后自动恢复 < 10秒
- [ ] 网络异常自动重试成功率 > 95%
- [ ] 7x24小时稳定运行无故障

## 总结

本方案采用Redis消息队列实现跨容器任务状态同步，具备高可靠性、高性能、易扩展的特点。通过双重消息保障机制确保状态更新不丢失，异步处理模式保证系统性能，标准化的消息格式便于后续扩展。

预计总开发周期：**10个工作日**
核心开发人员：**2人**
技术复杂度：**中等**
预期上线效果：**显著提升任务状态管理的可靠性和实时性**
